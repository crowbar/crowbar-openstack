[DEFAULT]
verbose = True
log_dir = /var/log/sahara
rpc_backend = sahara.openstack.common.rpc.impl_kombu

# Hostname or IP address that will be used to listen on.
# (string value)
#host=

# Port that will be used to listen on. (integer value)
#port=8386

# If set to True, Sahara will use floating IPs to communicate
# with instances. To make sure that all instances have
# floating IPs assigned in Nova Network set
# "auto_assign_floating_ip=True" in nova.conf.If Neutron is
# used for networking, make sure that all Node Groups have
# "floating_ip_pool" parameter defined. (boolean value)
#use_floating_ips=true

# Use Neutron or Nova Network (boolean value)
use_neutron=true

# Use network namespaces for communication (only valid to use in conjunction
# with use_neutron=True)
#use_namespaces=false


# Maximum length of job binary data in kilobytes that may be
# stored or retrieved in a single operation (integer value)
#job_binary_max_KB=5120

# Postfix for storing jobs in hdfs. Will be added to
# /user/hadoop/ (string value)
#job_workflow_postfix=

# enable periodic tasks (boolean value)
#periodic_enable=true



# Enables data locality for hadoop cluster.
# Also enables data locality for Swift used by hadoop.
# If enabled, 'compute_topology' and 'swift_topology'
# configuration parameters should point to OpenStack and Swift
# topology correspondingly. (boolean value)
#enable_data_locality=false

# File with nova compute topology. It should
# contain mapping between nova computes and racks.
# File format:
# compute1 /rack1
# compute2 /rack2
# compute3 /rack2
# (string value)
#compute_topology_file=etc/sahara/compute.topology

# File with Swift topology. It should contains mapping
# between Swift nodes and racks. File format:
# node1 /rack1
# node2 /rack2
# node3 /rack2
# (string value)
#swift_topology_file=etc/sahara/swift.topology



# Log request/response exchange details: environ, headers and
# bodies. (boolean value)
#log_exchange=false

# Print debugging output (set logging level to DEBUG instead
# of default WARNING level). (boolean value)
#debug=false

# Print more verbose output (set logging level to INFO instead
# of default WARNING level). (boolean value)
#verbose=false

# Log output to standard error. (boolean value)
#use_stderr=true

# (Optional) Name of log file to output to. If no default is
# set, logging will go to stdout. (string value)
#log_file=<None>

# (Optional) The base directory used for relative --log-file
# paths. (string value)
#log_dir=<None>

# Use syslog for logging. Existing syslog format is DEPRECATED
# during I, and will change in J to honor RFC5424. (boolean
# value)
#use_syslog=false

# Syslog facility to receive log lines. (string value)
#syslog_log_facility=LOG_USER

# List of plugins to be loaded. Sahara preserves the order of
# the list when returning it. (list value)
#plugins=vanilla,hdp,spark,cdh

[database]
connection=<%= @sql_connection %>

# The SQLAlchemy connection string used to connect to the
# database (string value)
#connection=<None>

[keystone_authtoken]
signing_dir = /var/cache/sahara/keystone-signing
admin_tenant_name = %SERVICE_TENANT_NAME%
admin_user = sahara
admin_password = %SERVICE_PASSWORD%
# Complete public Identity API endpoint (string value)
auth_uri = <%= @keystone_settings['public_auth_url'] %>

# Complete admin Identity API endpoint. This should specify
# the unversioned root endpoint eg. https://localhost:35357/
# (string value)
identity_uri = <%= @keystone_settings['admin_auth_url'] %>

# Keystone account username (string value)
admin_user = <%= @keystone_settings['service_user'] %>

# Keystone account password (string value)
admin_password = <%= @keystone_settings['service_password'] %>

# Keystone service account tenant name to validate user tokens
# (string value)
admin_tenant_name = <%= @keystone_settings['service_tenant'] %>
